<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="【Hadoop-3.2.2】HDFS集群搭建记录Author：R.G.  Last revision date：2021.04.20 转载或引用请注明出处 @rg4sun 目录[TOC] 服务器配置比较贫穷，要了三台服务器  内存：4G  CPU：4核  磁盘容量：50G  OS：CentOS7，内核版本uname看看   &#96;&#96;&#96;shell[root@localhost ~]# uname -aL">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="【Hadoop-3.2.2】HDFS集群搭建记录Author：R.G.  Last revision date：2021.04.20 转载或引用请注明出处 @rg4sun 目录[TOC] 服务器配置比较贫穷，要了三台服务器  内存：4G  CPU：4核  磁盘容量：50G  OS：CentOS7，内核版本uname看看   &#96;&#96;&#96;shell[root@localhost ~]# uname -aL">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104816757.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104806005.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104839476.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406105651054.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406110202908.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406110259204.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406111046371.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210406111301399.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210406111732804.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406112253261.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406112512473.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406112641924.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406113211838.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406113337299.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406113824498.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144153364.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144439223.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144959399.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144625235.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145154415.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145230807.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145335200.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145525216.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145556000.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406150104217.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406150605941.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406153151881.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406154456851.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406154533877.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406155250261.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406155417764.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210402161700233.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210402161821421.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210402163403073.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406165213739.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406165400697.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406170533739.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407161157002.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407161714225.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407163515130.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407165838308.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407172622998.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407192228030.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408100417641.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407192953377.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407194936452.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407195151370.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407201358175.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407204251510.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407201700326.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407202353118.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407202826790.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407203354150.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407205912729.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407210154434.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407210730330.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407210810970.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408101131840.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408101201689.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408101647276.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102311486.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102458947.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102633667.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102856685.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408104831785.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105124289.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105434672.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105711851.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105743289.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110045768.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110612993.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110700744.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110848073.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210408111349482.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408111825924.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408111932440.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408112134607.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210410153156096.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210410154703559.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210410154719887.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412105741668.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412110444510.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412110932559.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412111034624.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412111205878.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412111537698.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412111713853.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412111747692.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412111912144.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412111942913.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412112111228.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412112234790.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412113939626.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412114409565.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412114731344.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412114841257.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412115051301.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412122424773.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412122859868.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420112514688.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412123445406.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412124003275.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210412124059850.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS集群搭建.assets/image-20210420103741848.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420103900740.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105427601.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105548350.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105641583.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105657842.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420113826254.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420113844349.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420114040018.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420114127098.png">
<meta property="og:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420114334082.png">
<meta property="article:published_time" content="2021-04-21T10:14:56.768Z">
<meta property="article:modified_time" content="2021-04-21T07:36:39.439Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104816757.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-HDFS集群搭建" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" class="article-date">
  <time class="dt-published" datetime="2021-04-21T10:14:56.768Z" itemprop="datePublished">2021-04-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="【Hadoop-3-2-2】HDFS集群搭建记录"><a href="#【Hadoop-3-2-2】HDFS集群搭建记录" class="headerlink" title="【Hadoop-3.2.2】HDFS集群搭建记录"></a>【Hadoop-3.2.2】HDFS集群搭建记录</h1><p><strong>Author：R.G.</strong> </p>
<p><strong>Last revision date：2021.04.20</strong></p>
<p><strong>转载或引用请注明出处 @<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41709370">rg4sun</a></strong></p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>[TOC]</p>
<h2 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h2><p>比较贫穷，要了三台服务器</p>
<ul>
<li><p>内存：4G</p>
</li>
<li><p>CPU：4核</p>
</li>
<li><p>磁盘容量：50G</p>
</li>
<li><p>OS：CentOS7，内核版本uname看看</p>
<ul>
<li><blockquote>
<p>```shell<br>[root@localhost ~]# uname -a<br>Linux localhost.localdomain 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux<br>[root@localhost ~]# </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## Java环境安装并配置</span><br><span class="line"></span><br><span class="line">此部分参考  [Linux下Java8环境(jdk1.8.0_281)安装记录](..&#x2F;JAVA环境安装&#x2F;jdk1.8.0_281.md) </span><br><span class="line"></span><br><span class="line">顺带这里再安装一下 Maven，此处不做记录了，之前记录过</span><br><span class="line"></span><br><span class="line">## 重设主机名并配置hosts</span><br><span class="line"></span><br><span class="line">### 更改hostname</span><br><span class="line"></span><br><span class="line">为了便于标识不同节点的身份，这里我将各节点的主机名重设一下</span><br><span class="line"></span><br><span class="line">先查看一下当前的主机名：</span><br><span class="line"></span><br><span class="line">&lt;img src&#x3D;&quot;HDFS集群搭建.assets&#x2F;image-20210406103445300.png&quot; alt&#x3D;&quot;image-20210406103445300&quot; style&#x3D;&quot;zoom:100%;&quot; &#x2F;&gt;</span><br><span class="line"></span><br><span class="line">可以看到，三个节点的主机名都是&#96;localhost.localdomain&#96;（节点2、3都是，这里只截了节点1的图）</span><br><span class="line"></span><br><span class="line">如何修改hostname参考：[3种方法更改Linux系统的主机名(hostname) ](https:&#x2F;&#x2F;www.linuxdashen.com&#x2F;3种方法更改linux系统的主机名hostname)</span><br><span class="line"></span><br><span class="line">这里我使用如下命令更改hostname，改完需要重启：</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;shell</span><br><span class="line">[root@localhost rg_things]# hostnamectl set-hostname master</span><br><span class="line">[root@localhost rg_things]# reboot </span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
</li>
</ul>
<p>以上是改node1的主机名为master，同理改node2、3为 slave1、slave2</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104816757.png" alt="image-20210406104816757"></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104806005.png" alt="image-20210406104806005"></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406104839476.png" alt="image-20210406104839476"></p>
<h3 id="配hosts文件"><a href="#配hosts文件" class="headerlink" title="配hosts文件"></a>配hosts文件</h3><p>依次在master、slave1、slave2节点上执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim /etc/hosts</span></span><br></pre></td></tr></table></figure>

<p>写入如下三行（10.x 那三行，注意我这是内网ip，如果你的服务器是公网ip注意保护打马赛克）</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406105651054.png" alt="image-20210406105651054"></p>
<p>检测ping名称是否能ping通：</p>
<p>master ping slave1、slave2</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406110202908.png" alt="image-20210406110202908"></p>
<p>能ping通，那基本上反向ping也能的，试一个slave1 ping master</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406110259204.png" alt="image-20210406110259204"></p>
<h2 id="SSH环境安装并配置"><a href="#SSH环境安装并配置" class="headerlink" title="SSH环境安装并配置"></a>SSH环境安装并配置</h2><h3 id="SSH服务安装"><a href="#SSH服务安装" class="headerlink" title="SSH服务安装"></a>SSH服务安装</h3><p>首先查看一下本机有没有安装ssh服务（要有server和client服务）</p>
<p>由于我的三台服务器初始配置是完全一样的，这里检查master节点即可</p>
<p>使用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> yum list installed | grep ssh</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406111046371.png" alt="image-20210406111046371"></p>
<p>可以看到，client和server都安装了</p>
<p>但是为了保险起见，我再次执行了一下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> yum install openssh-server</span></span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210406111301399.png" alt="image-20210406111301399" style="zoom:80%;" />

<p>结果提示，要安装更新，那就安装一下更新，在slave1、2也同理</p>
<h3 id="配置SSH免密登录"><a href="#配置SSH免密登录" class="headerlink" title="配置SSH免密登录"></a>配置SSH免密登录</h3><p>为何需要配置免密登录：</p>
<img src="HDFS集群搭建.assets/image-20210406111732804.png" alt="image-20210406111732804" style="zoom:80%;" />

<p>先试一试在master ssh登录 slave1：</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406112253261.png" alt="image-20210406112253261"></p>
<p>可以看到，当前需要密码才能在master登录slave1</p>
<p>下面配置免密登录，使得master能免密登录slave1、2（反向无需做免密登录）</p>
<p>首先查看一下当前的<code>~/.ssh</code>路径内有些啥玩意</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406112512473.png" alt="image-20210406112512473"></p>
<p>可以看到没有配置过本机的公钥、私钥，只有个<code>konwn_hosts</code>文件，处于好奇我也打开看看里面是啥</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406112641924.png" alt="image-20210406112641924"></p>
<p>哦~有意思，里面记录了slave1 的ip和一串 sha-2的加密字符，盲猜是因为刚刚在master登录过一次slave1的原因，这里不继续深究了</p>
<h4 id="在master节点执行"><a href="#在master节点执行" class="headerlink" title="在master节点执行"></a>在master节点执行</h4><p>下面在master节点生成1024位的RSA公私密钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# ssh-keygen -b 1024 -t rsa</span><br></pre></td></tr></table></figure>

<p>执行上述语句，一路回车（默认配置，不回车的话，你可以配置生成路径啊之类的，可以但没必要）</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406113211838.png" alt="image-20210406113211838"></p>
<p>下面再查看一下<code>~/.ssh</code>内容</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406113337299.png" alt="image-20210406113337299"></p>
<p>可以看到现在新增了2文件，<code>id_rsa</code> 是本机的私钥，<code>id_rsa.pub</code> 是本机公钥（public么，好理解的）</p>
<h4 id="在slave1、2执行"><a href="#在slave1、2执行" class="headerlink" title="在slave1、2执行"></a>在slave1、2执行</h4><p>同样需要在2个slave节点生成1024位的RSA公私密钥：</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406113824498.png" alt="image-20210406113824498"></p>
<p>（一个细节：可以看到没有在slave1上登录过别的机子，所以没有 <code>known_hosts</code> 文件）</p>
<h4 id="回到master执行"><a href="#回到master执行" class="headerlink" title="回到master执行"></a>回到master执行</h4><p>在master执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ssh-copy-id slave1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ssh-copy-id slave2</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144153364.png" alt="image-20210406144153364"></p>
<p>在master的<code>.ssh/</code>中没有新增文件欸，看看 <code>known_hosts</code> 内容有没有变化</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144439223.png" alt="image-20210406144439223"></p>
<p>发现 <code>known_hosts</code> 多了一条slave2 的信息</p>
<p>在slave1、2的<code>.ssh/</code>路径中，出现了一个新文件 <code>authorized_keys</code></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144959399.png" alt="image-20210406144959399"></p>
<p>查看 <code>authorized_keys</code>内容，发现里面是 master 的公钥内容</p>
<p>测试一下 master 能否免密登录 slave1、2</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406144625235.png" alt="image-20210406144625235"></p>
<p>可以看到，能免密登录了</p>
<h4 id="从机之间互相免密登录"><a href="#从机之间互相免密登录" class="headerlink" title="从机之间互相免密登录"></a>从机之间互相免密登录</h4><p>在slave1执行：</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145154415.png" alt="image-20210406145154415"></p>
<p>多了一个<code>know_hosts</code></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145230807.png" alt="image-20210406145230807"></p>
<p>里面就是slave 2的信息</p>
<p>此时，查看slave 2的 <code>authorized_keys</code></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145335200.png" alt="image-20210406145335200"></p>
<p>可以看到，slave2 的  <code>authorized_keys</code>中 多了slave1的公钥</p>
<p>同理，在slave 3执行上述操作</p>
<p>测试两从机之间的免密登录</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145525216.png" alt="image-20210406145525216"></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406145556000.png" alt="image-20210406145556000"></p>
<p>大成功！✌</p>
<h4 id="补充：master自己免密登录自己"><a href="#补充：master自己免密登录自己" class="headerlink" title="补充：master自己免密登录自己"></a>补充：master自己免密登录自己</h4><p>为了使从master启动hadoop时避免多次输入密码，这里再做一步，让master可以免密登录自己，操作方法和上面一样</p>
<p>在master执行：</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406150104217.png" alt="image-20210406150104217"></p>
<p>可以看到 master 的 <code>.ssh/</code> 中多了 <code>authorized_keys</code>文件，并且内容是 master自己的公钥</p>
<h4 id="检查-authorized-keys-文件权限"><a href="#检查-authorized-keys-文件权限" class="headerlink" title="检查  authorized_keys  文件权限"></a>检查  <code>authorized_keys</code>  文件权限</h4><p>顺便看一下 <code>authorized_keys</code> 文件的权限（三个节点都要看）</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406150605941.png" alt="image-20210406150605941"></p>
<p>要求对其是可读可写的，否则可能会遇到问题</p>
<h4 id="知识补充"><a href="#知识补充" class="headerlink" title="知识补充"></a>知识补充</h4><p>改权限使用 <code>chmod &lt;xxx&gt;  &lt;filename&gt;</code> 命令，其中，xxx是三个10进制数（有效取值为0-7），第一位对应 owner（文件所有者）的权限、第二位对应 Group（文件所在组）的权限、第三位对应 Other Users（其他用户）的权限。</p>
<p>每个数，3bit定义，分别为rwx，1表示开启对应权限，0则关闭</p>
<p>如：chmod 760 testFile </p>
<p>7 = 0b111 表示 owner 可读可写可执行</p>
<p>6=0b110 表示 Group 可读可写不可执行</p>
<p>0=0b000 表示其他用户 没有任何权限</p>
<p>参考资料：<a target="_blank" rel="noopener" href="https://www.runoob.com/linux/linux-comm-chmod.html">Linux chmod 命令 | 菜鸟教程 (runoob.com)</a></p>
<h2 id="配置集群节点时钟同步"><a href="#配置集群节点时钟同步" class="headerlink" title="配置集群节点时钟同步"></a>配置集群节点时钟同步</h2><p>可以通过clock查看一下当前的时钟</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406153151881.png" alt="image-20210406153151881"></p>
<p>我看了我的三台机子时间基本是一致的，但是为了保证三台机子时钟同步，还是配置一下（如果时钟不同步，可能会导致节点之间访问超时）</p>
<p>测试一下系统有没有ntpdate命令</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406154456851.png" alt="image-20210406154456851"></p>
<p>没有则装</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406154533877.png" alt="image-20210406154533877"></p>
<p>补充：<em>NTP服务器</em>【Network Time Protocol（<em>NTP</em>）】是用来使计算机时间同步化的一种协议，它可以使计算机对其<em>服务器</em>或时钟源（如石英钟，GPS等等)做同步化，它可以提供高精准度的时间</p>
<p>使用如下命令同步时间：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ntpdate cn.pool.ntp.org</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406155250261.png" alt="image-20210406155250261"></p>
<blockquote>
<p>直接跑上述命令只是强制性的将系统时间设置为ntp服务器时间。如果CPU Tick有问题，只是治标不治本。所以，一般配合cron命令，来进行定期同步设置。</p>
<p>参考自：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/williamjie/p/10768657.html">Linux系统时间同步方法小结</a></p>
</blockquote>
<p>使用如下命令配置定期同步时间：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> crontab -e</span></span><br></pre></td></tr></table></figure>

<p>配置以下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0 1 * * * /usr/sbin/ntpdate cn.pool.ntp.org</span><br><span class="line">分 时 日 月 周 命令 参数 【这一行不用写入配置，上述内容表示 ntpdate命令 从参数提供的服务器 每小时更新一次时钟】 </span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406155417764.png" alt="image-20210406155417764"></p>
<p><strong>注意：上述操作 master、slave1、2都要执行</strong></p>
<p><strong>==【👉再次强调：上述操作三台机子都需要执行】==</strong></p>
<h2 id="下载Hadoop安装包"><a href="#下载Hadoop安装包" class="headerlink" title="下载Hadoop安装包"></a>下载Hadoop安装包</h2><p>进入官网 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/releases.html%EF%BC%8C%E4%B8%8B%E8%BD%BDrelease%E7%89%88%E6%9C%AC">https://hadoop.apache.org/releases.html，下载release版本</a></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210402161700233.png" alt="image-20210402161700233"></p>
<p>这里我选用了当前最新的3.2.2版本的 binary版本，点击</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210402161821421.png" alt="image-20210402161821421"></p>
<p>这里我直接在服务器中用 wget下载，三台机子都需要执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> wget https://downloads.apache.org/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210402163403073.png" alt="image-20210402163403073"></p>
<p>【上图是刚拿到服务器跑的，所以hostname还没改】</p>
<p><strong>==【👉再次强调：上述操作三台机子都需要执行】==</strong></p>
<h2 id="解压Hadoop安装包"><a href="#解压Hadoop安装包" class="headerlink" title="解压Hadoop安装包"></a>解压Hadoop安装包</h2><p>先将hadoop的tar包迁移到 <code>/opt</code>路径下</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406165213739.png" alt="image-20210406165213739"></p>
<p>补充：为啥迁移到opt</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhidao.baidu.com/question/1511380186430413580.html">百度知道解释</a>：opt是主机额外安装软件所摆放的目录。默认是空的。 一般安装软件的时候，可以自己指定安装到这个目录下，便于查找和管理</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/lesroad/p/9737954.html">linux中的/usr,/var,/opt目录详解</a></p>
</blockquote>
<p>解压tar包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> tar -zxvf hadoop-3.2.2.tar.gz</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406165400697.png" alt="image-20210406165400697"></p>
<p><strong>==【👉再次强调：上述操作三台机子都需要执行】==</strong></p>
<h2 id="配置Hadoop环境变量"><a href="#配置Hadoop环境变量" class="headerlink" title="配置Hadoop环境变量"></a>配置Hadoop环境变量</h2><p><strong>三个节点都执行</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure>

<p>写入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop-3.2.2 setting by R.G.  2021.04.06</span></span><br><span class="line">export HADOOP_HOME=/opt/hadoop-3.2.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>然后记得source 一下生效配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p>检验一下Hadoop命令是否可用了</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210406170533739.png" alt="image-20210406170533739"></p>
<p>可用了，由此Hadoop安装好了，下面需要进行配置</p>
<p><strong>==【👉再次强调：上述操作三台机子都需要执行】==</strong></p>
<h2 id="Hadoop配置【重点】"><a href="#Hadoop配置【重点】" class="headerlink" title="Hadoop配置【重点】"></a>Hadoop配置【重点】</h2><p><strong>==🍀🍀🍀注意注意：本小节<code>Hadoop配置【重点】</code> 的所有配置都 <em>只需在 master主节点上进行配置</em> ，两个从节点不用配置，直接拿master配置好的文件去替换就好了==</strong></p>
<p>进入安装的hadoop路径中的<code> etc/hadoop</code> 去修改配置文件，注意不是 Linux的 <code>/etc</code></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407161157002.png" alt="image-20210407161157002"></p>
<p>可以看到里面有一堆文件，注意几个 后缀为 <code>.example</code> 的文件，这些给的是配置样例，建议如果要配置对应文件，创建一个不带<code>.example</code>后缀的同名文件，然后复制原先带有<code>.example</code>后缀的文件内容，然后再修改配置</p>
<p>这里插播一点关于hadoop各个文件夹作用的小知识：</p>
<table>
<thead>
<tr>
<th align="center">文件夹</th>
<th align="center">功能</th>
</tr>
</thead>
<tbody><tr>
<td align="center">bin</td>
<td align="center">存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本</td>
</tr>
<tr>
<td align="center">etc</td>
<td align="center">Hadoop的配置文件目录，存放Hadoop的配置文件</td>
</tr>
<tr>
<td align="center">lib</td>
<td align="center">存放Hadoop的本地库（对数据进行压缩解压缩功能）</td>
</tr>
<tr>
<td align="center">sbin</td>
<td align="center">存放启动或停止Hadoop相关服务的脚本</td>
</tr>
<tr>
<td align="center">share</td>
<td align="center">存放Hadoop的依赖jar包、文档、和官方案例</td>
</tr>
</tbody></table>
<h3 id="配置-hadoop-env-sh-文件"><a href="#配置-hadoop-env-sh-文件" class="headerlink" title="配置 hadoop-env.sh 文件"></a>配置 hadoop-env.sh 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure>

<p>在该文件中修改Java环境的路径</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407161714225.png" alt="image-20210407161714225"></p>
<p>翻到这里，然后取消注释，配置本机的JAVA_HOME【就是之前你安装java时配置过的】</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407163515130.png" alt="image-20210407163515130"></p>
<p>这里我使用JAVA_HOME变量配置，如果不行的话，就启用第二行直接写绝对路径的配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> JAVA setting by R.G. on 2021.04.07, <span class="keyword">if</span> not work, <span class="built_in">enable</span> the second line</span></span><br><span class="line">export JAVA_HOME=$JAVA_HOME</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_281</span></span><br></pre></td></tr></table></figure>

<p>然后配置一下HADOOP_HOME</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407165838308.png" alt="image-20210407165838308"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> HADOOP_HOME setting by R.G. on 2021.04.07.If not work, <span class="built_in">enable</span> the second line</span></span><br><span class="line">export HADOOP_HOME=$HADOOP_HOME</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> HADOOP_HOME=/opt/hadoop-3.2.2</span></span><br></pre></td></tr></table></figure>

<p>修改好了之后，保存并退出</p>
<h3 id="配置-core-site-xml-文件"><a href="#配置-core-site-xml-文件" class="headerlink" title="配置 core-site.xml 文件"></a>配置 core-site.xml 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407172622998.png" alt="image-20210407172622998"></p>
<p>在<code>&lt;configuration&gt;</code>标签内部配置如下内容：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Setting by R.G. on 2021.04.07 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- </span></span><br><span class="line"><span class="comment">	指定HDFS中NameNode的地址,value标签里写它的ip:port，</span></span><br><span class="line"><span class="comment">	ip之前映射成master了可以填字符串master</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- </span></span><br><span class="line"><span class="comment">	指定Hadoop运行时产生文件的存储目录, 可以随意指定，</span></span><br><span class="line"><span class="comment">	这个文件夹在配置前是没有的，按照常规的设计逻辑来说，</span></span><br><span class="line"><span class="comment">	运行hadoop应该是会自己生成的，</span></span><br><span class="line"><span class="comment">	如果没有生成，报错了，那就提前mkdir这个文件夹</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop-3.2.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407192228030.png" alt="image-20210407192228030"></p>
<p>配置完成，保存并退出</p>
<p>这里为了稳妥起见，创建<code>/opt/hadoop-3.2.2/data/tmp</code>这个数据文件夹，**==以下操作三台机子都要执行==**</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/hadoop-3.2.2</span><br><span class="line">mkdir data</span><br><span class="line">cd data</span><br><span class="line">mkdir tmp</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408100417641.png" alt="image-20210408100417641"></p>
<p>记得master机子的路径再切回<code>/hadoop-3.2.2/etc/hadoop</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /hadoop-3.2.2/etc/hadoop</span><br></pre></td></tr></table></figure>

<h3 id="配置-hdfs-site-xml-文件"><a href="#配置-hdfs-site-xml-文件" class="headerlink" title="配置 hdfs-site.xml 文件"></a>配置 hdfs-site.xml 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407192953377.png" alt="image-20210407192953377"></p>
<p>在<code>&lt;configuration&gt;</code>标签内部配置如下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Setting by R.G. on 2021.04.07 --&gt;</span><br><span class="line">&lt;!-- </span><br><span class="line">	指定HDFS中保存副本的数量</span><br><span class="line">	我只有两台从机，这里填2，也就是说同一份文件会在两个节点上各自保留一份</span><br><span class="line">	我猜测（有待验证）：比如10台从机，你配3，那同一个文件，它会在3个节点上各保留一份</span><br><span class="line">	一般设置2-3，太大会占容量，配1就没有副本了，影响容错能力</span><br><span class="line">--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">		&lt;value&gt;2&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- </span><br><span class="line">	指定Hadoop辅助NameNode主机配置，就是master那个NameNode挂掉了，这里这个会顶上 </span><br><span class="line">	由于我只有三台机子，master、slave1、slave2，所以就不配备用NameNode了，下面注释掉了</span><br><span class="line">--&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;</span><br><span class="line">      下面填入:</span><br><span class="line">      		备用NameNode的ip（或者hosts里映射的名字）:端口（自定义）</span><br><span class="line">      		方括号记得去掉</span><br><span class="line">      		开启这个配置，请把此处的注释加上html注释符号</span><br><span class="line">      &lt;value&gt;[ip or name of secondary NameNode]:[port]&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">--&gt;</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407194936452.png" alt="image-20210407194936452"></p>
<p>配置完成，保存并退出</p>
<h3 id="配置-mapred-site-xml（MapReduce配置文件）"><a href="#配置-mapred-site-xml（MapReduce配置文件）" class="headerlink" title="配置  mapred-site.xml（MapReduce配置文件）"></a>配置  mapred-site.xml（MapReduce配置文件）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim  mapred-site.xml</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407195151370.png" alt="image-20210407195151370"></p>
<p>在<code>&lt;configuration&gt;</code>标签内部配置如下内容：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Setting by R.G. on 2021.04.07 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定Mapreduce运行在Yarn上，有三种可能的参数：class、yarn、local --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--hadoop3 配置以下内容，我看的视频教程是2.7.7，这部分没配--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407201358175.png" alt="image-20210407201358175"></p>
<p>对了，顺便看一下配的路径是否存在，内容有些啥</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407204251510.png" alt="image-20210407204251510"></p>
<h3 id="配置-yarn-site-xml-文件"><a href="#配置-yarn-site-xml-文件" class="headerlink" title="配置 yarn-site.xml 文件"></a>配置 yarn-site.xml 文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407201700326.png" alt="image-20210407201700326"></p>
<p>在<code>&lt;configuration&gt;</code>标签内部配置如下内容：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Setting by R.G. on 2021.04.07 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址，这里设置成主节点master的地址（ip或者名称） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407202353118.png" alt="image-20210407202353118"></p>
<p>配置完成，保存并退出</p>
<h3 id="配置-slaves-文件（3-x版本以上改名为-workers）"><a href="#配置-slaves-文件（3-x版本以上改名为-workers）" class="headerlink" title="配置 slaves 文件（3.x版本以上改名为 workers）"></a>配置 slaves 文件（3.x版本以上改名为 workers）</h3><p>注意：还是在<code> etc/hadoop</code> 路径下哦😝</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim workers</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407202826790.png" alt="image-20210407202826790"></p>
<p>把从机的名称（或者ip）填入即可，主节点（我这名称为master）也可以填入，不影响（但没必要填）</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407203354150.png" alt="image-20210407203354150"></p>
<p>配置完成，保存并退出</p>
<h3 id="拷贝以上配置文件到从节点"><a href="#拷贝以上配置文件到从节点" class="headerlink" title="拷贝以上配置文件到从节点"></a>拷贝以上配置文件到从节点</h3><p>在开始之前，还记得配置文件在那个路径下么？</p>
<p>对了，就在<code>$HADOOP_HOME/etc</code> 下面，你真棒👍（傻里傻气的。，。估计没记得吧？）</p>
<p>首先，需要把slave1、2两个从节点的配置文件备份，这里我直接将其改名成 <code>etc-initial</code></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407205912729.png" alt="image-20210407205912729"></p>
<p>然后，将主节点master的整个<code>etc</code> 文件夹直接分发到两个从节点的 hadoop安装路径里（<code>$HADOOP_HOME</code>）</p>
<p>在master上操作，先退回到hadoop的跟路径：</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407210154434.png" alt="image-20210407210154434"></p>
<p>使用 <code>scp</code> 命令发送 <code>etc</code>文件夹 给 slave1、2：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r etc slave1:/opt/hadoop-3.2.2</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407210730330.png" alt="image-20210407210730330"></p>
<p>去slave1上看看有没有拿到</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210407210810970.png" alt="image-20210407210810970"></p>
<p>可以看到，成功传送到了（然后其实，可以删掉<code>etc-initial</code>文件夹了，不放心你可以留着）</p>
<p><strong>==注意：记得还要再传送一份给slave2哦==</strong></p>
<p>知识补充：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.runoob.com/linux/linux-comm-scp.html">Linux scp命令</a></p>
<p>Linux scp 命令用于 Linux 之间复制文件和目录。</p>
<p>scp 是 secure copy 的缩写, scp 是 linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。</p>
<p>scp 是加密的，<a target="_blank" rel="noopener" href="https://www.runoob.com/linux/linux-comm-rcp.html">rcp</a> 是不加密的，scp 是 rcp 的加强版。</p>
<p>-r： 递归复制整个目录。</p>
</blockquote>
<p>到此，HDFS集群配置好了，yeah✌✌✌</p>
<h2 id="Hadoop-格式化"><a href="#Hadoop-格式化" class="headerlink" title="Hadoop 格式化"></a>Hadoop 格式化</h2><p>格式化文件系统一般只建议在搭建完格式化一次，格式化操作在Namenode上执行（也就是我这的主节点master）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408101131840.png" alt="image-20210408101131840"></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408101201689.png" alt="image-20210408101201689"></p>
<p>可以看到格式化完成（如果出现Exception/Error则发生问题）</p>
<p><strong>==👉 强调：上述格式化命令，只在master执行，并且就执行这一次==</strong></p>
<p>顺便，看看数据文件夹有没有产生数据</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408101647276.png" alt="image-20210408101647276"></p>
<p>可以看到产生了一些数据</p>
<h2 id="Hadoop启动"><a href="#Hadoop启动" class="headerlink" title="Hadoop启动"></a>Hadoop启动</h2><p>进入脚本文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd $HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102311486.png" alt="image-20210408102311486"></p>
<p>启动前，可以先使用以下命令查看以下HDFS集群状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfsadmin -report</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102458947.png" alt="image-20210408102458947"></p>
<p>哦，他说这个命令已经被弃用了，应该是3.x版本改了，改用下面的命令查看集群状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -report</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102633667.png" alt="image-20210408102633667"></p>
<p>可以看到，当前执行这条命令显示 连接异常，因为集群还没有启动，下面讲解如何启动集群</p>
<p>启动所有</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>

<p>也可以分步启动：</p>
<ul>
<li><p>Step 1 启动文件系统：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li><p>Step 2 启动yarn计算框架（控制mapreduce的）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-yarn.sh</span><br></pre></td></tr></table></figure></li>
</ul>
<p>这里，我选用启动所用</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408102856685.png" alt="image-20210408102856685"></p>
<h3 id="启动错误❌"><a href="#启动错误❌" class="headerlink" title="启动错误❌"></a>启动错误❌</h3><p>出现错误，提示 <code>HDFS_NAMENODE_USER</code> 、<code> HDFS_SECONDARYNAMENODE_USER</code>、<code>YARN_RESOURCEMANAGER_USER</code>、<code>YARN_RESOURCEMANAGER_USER</code> 没有定义，说明之前配置这些部分没有配置（我是主要参考2.7.7的教程来的，里面没有提到这些配置）</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="在master上执行"><a href="#在master上执行" class="headerlink" title="在master上执行"></a>在master上执行</h4><blockquote>
<p>The root cause of this problem,</p>
<p>hadoop install for different user and you start yarn service for different user. OR<br>in hadoop config’s hadoop-env.sh specified HDFS_NAMENODE_USER and HDFS_DATANODE_USER user is something else.<br>Hence we need to correct and make it consistent at every place. So a simple solution of this problem is to edit your hadoop-env.sh file and add the user-name for which you want to start the yarn service. So go ahead and edit $HADOOP_HOME/etc/hadoop/hadoop-env.sh by adding the following lines</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>

<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/ystyaoshengting/article/details/103026872">ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.</a></p>
</blockquote>
<p>切换路径到<code>$HADOOP_HOME/etc/hadoop/</code>，执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408104831785.png" alt="image-20210408104831785"></p>
<p>翻到最后，他这里提示了 通过控制 <code> (command)_(subcommand)_USER</code>格式的参数，可以锁定shell的命令仅允许指定的用户执行</p>
<p>另外，这里插播一个小知识：vim开启行号命令为 <code>:set nu</code></p>
<p>追加以下配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105124289.png" alt="image-20210408105124289"></p>
<p>保存并退出</p>
<p>别忘了，这里只是修改了master的配置，两个slave也要相应修改</p>
<h4 id="传送修改的配置到从节点"><a href="#传送修改的配置到从节点" class="headerlink" title="传送修改的配置到从节点"></a>传送修改的配置到从节点</h4><p>首先，先在slave1、2上把原来的 <code>etc</code> 文件夹删除</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf etc</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105434672.png" alt="image-20210408105434672"></p>
<p>上述操作slave2也执行一遍</p>
<p>再回到master，传送配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r etc slave1:/opt/hadoop-3.2.2</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105711851.png" alt="image-20210408105711851"></p>
<p>去slave1上看看有没有拿到</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408105743289.png" alt="image-20210408105743289"></p>
<p>可以看到，成功传送到了</p>
<p><strong>==注意：记得还要再传送一份给slave2哦==</strong></p>
<h3 id="再次测试启动"><a href="#再次测试启动" class="headerlink" title="再次测试启动"></a>再次测试启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110045768.png" alt="image-20210408110045768"></p>
<p>好家伙，还错</p>
<h3 id="再次启动错误❌"><a href="#再次启动错误❌" class="headerlink" title="再次启动错误❌"></a>再次启动错误❌</h3><p>可以看到报了 <code>JAVA_HOME </code> 未定义，注意这里的应该是 <code>hadoop-env.sh</code> 中的java配置</p>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><p>查看一下该配置文件</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110612993.png" alt="image-20210408110612993"></p>
<p>之前是配过了呀，难道是引用的问题吗</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110700744.png" alt="image-20210408110700744"></p>
<p>系统有 JAVA_HOME 这个变量没问题，要么直接启用绝对路径试试看</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408110848073.png" alt="image-20210408110848073"></p>
<p>直接改用绝对路径，顺便 <code>HADOOP_HOME</code> 也改用绝对路径</p>
<p><strong>==同样，改完master配置后，再次把slave1、2的etc替换掉，这里不再截图记录了==</strong></p>
<h3 id="再再次测试启动-✔"><a href="#再再次测试启动-✔" class="headerlink" title="再再次测试启动 ✔"></a>再再次测试启动 ✔</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210408111349482.png" alt="image-20210408111349482" style="zoom:80%;" />

<p>终于启动成功了，耶耶耶✌</p>
<p>可以看一下进程是否存在</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408111825924.png" alt="image-20210408111825924"></p>
<p>可以看到有hadoop相关的进程了</p>
<p>查看一下集群状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -report</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408111932440.png" alt="image-20210408111932440"></p>
<p>注意启动操作只需要在主节点Namenode（也就是我的master）上执行就好，从节点自己挂载的</p>
<p>顺便在从节点执行查看一下</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210408112134607.png" alt="image-20210408112134607"></p>
<p>可以看到，从节点只有 <code>Datanode</code>、 <code>NodeManger</code> 2个进程，并且 <code>hdfs dfsadmin -report</code> 命令是无效的（想想也是，只需要在主节点监控就好）</p>
<p>由此，整个集群启动成功</p>
<h2 id="使用官方测试用例测试集群使用"><a href="#使用官方测试用例测试集群使用" class="headerlink" title="使用官方测试用例测试集群使用"></a>使用官方测试用例测试集群使用</h2><p>官方提供了一个java写的测试用例，</p>
<p>进入一下路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd $HADOOP_HOME/share/hadoop/mapreduce</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210410153156096.png" alt="image-20210410153156096"></p>
<p>使用 <code>hadoop-mapreduce-examples-3.2.2.jar</code>，计算圆周率 $\pi$ （这个程序有很多测试用例，计算圆周率只是其中一个功能，是用蒙特卡洛法计算的），使用一下命令运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-mapreduce-examples-3.2.2.jar pi 10 10</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210410154703559.png" alt="image-20210410154703559"></p>
<img src="HDFS集群搭建.assets/image-20210410154719887.png" alt="image-20210410154719887" style="zoom:67%;" />

<p>可以看到成功跑完了，说明HDFS集群功能是正常能运行的，大成功✌！</p>
<h2 id="Web-UI-监控HDFS集群给状态"><a href="#Web-UI-监控HDFS集群给状态" class="headerlink" title="Web UI 监控HDFS集群给状态"></a>Web UI 监控HDFS集群给状态</h2><p>有两种方法，建议直接看方法2（不行再用1）</p>
<h3 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h3><p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412105741668.png" alt="image-20210412105741668"></p>
<p>注意到，每次使用XSehll登录服务器的时候，会报这样一个Warning，而这里使用Web UI 就需要解决这个warning</p>
<img src="HDFS集群搭建.assets/image-20210412110444510.png" alt="image-20210412110444510" style="zoom:50%;" />

<p>检查这个设置是否打开，然后需要下载Xmanager</p>
<h4 id="安装Firefox"><a href="#安装Firefox" class="headerlink" title="安装Firefox"></a>安装Firefox</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install firefox -y</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412110932559.png" alt="image-20210412110932559" style="zoom:67%;" />

<h4 id="下载X11相关包"><a href="#下载X11相关包" class="headerlink" title="下载X11相关包"></a>下载X11相关包</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install xorg-x11-xauth -y</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412111034624.png" alt="image-20210412111034624" style="zoom:67%;" />

<p>然后可以下一个Xclock检查 X11功能是否能运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install xclock -y</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412111205878.png" alt="image-20210412111205878" style="zoom:67%;" />

<h4 id="配置ssh服务中和X11相关的配置"><a href="#配置ssh服务中和X11相关的配置" class="headerlink" title="配置ssh服务中和X11相关的配置"></a>配置ssh服务中和X11相关的配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<p>翻到如下位置，取消注释，启用配置</p>
<img src="HDFS集群搭建.assets/image-20210412111537698.png" alt="image-20210412111537698" style="zoom:67%;" />

<p>保存并退出</p>
<h4 id="重启ssh服务"><a href="#重启ssh服务" class="headerlink" title="重启ssh服务"></a>重启ssh服务</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart sshd</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412111713853.png" alt="image-20210412111713853"></p>
<p>测试一下 Xclock能否使用</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412111747692.png" alt="image-20210412111747692"></p>
<p>可以看到此时还不能dispaly，应该需要退出当前ssh连接，重新连接服务器</p>
<h4 id="XShell重新连接服务器"><a href="#XShell重新连接服务器" class="headerlink" title="XShell重新连接服务器"></a>XShell重新连接服务器</h4><p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210412111912144.png" alt="image-20210412111912144"></p>
<p>直接×掉当前连接</p>
<img src="HDFS集群搭建.assets/image-20210412111942913.png" alt="image-20210412111942913" style="zoom:80%;" />

<p>双击服务器重新连接</p>
<img src="HDFS集群搭建.assets/image-20210412112111228.png" alt="image-20210412112111228" style="zoom:80%;" />

<p>可以看到没有之前的warning了，但是提示你有一个文件不存在，我们直接忽略这个，因为它会自动创建的</p>
<p>测试使用xclock</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xclock</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412112234790.png" alt="image-20210412112234790" style="zoom:80%;" />

<p>此时提示我们需要安装 Xmanager</p>
<h4 id="下载安装Xmanager7"><a href="#下载安装Xmanager7" class="headerlink" title="下载安装Xmanager7"></a>下载安装Xmanager7</h4><img src="HDFS集群搭建.assets/image-20210412113939626.png" alt="image-20210412113939626" style="zoom:80%;" />

<p>他会将试用版下载链接发送到你的邮箱里</p>
<img src="HDFS集群搭建.assets/image-20210412114409565.png" alt="image-20210412114409565" style="zoom:80%;" />

<p>执行安装（破解的话，暂时我没去折腾）</p>
<p>安装完了，桌面会生成一个文件夹</p>
<img src="HDFS集群搭建.assets/image-20210412114731344.png" alt="image-20210412114731344" style="zoom:80%;" />

<p>再测试一下xclock</p>
<img src="HDFS集群搭建.assets/image-20210412114841257.png" alt="image-20210412114841257" style="zoom:80%;" />

<p>此时会弹出一个小钟，说明X11服务已经能使用了</p>
<h4 id="使用firefox访问HDFS监控页面"><a href="#使用firefox访问HDFS监控页面" class="headerlink" title="使用firefox访问HDFS监控页面"></a>使用firefox访问HDFS监控页面</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firefox</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412115051301.png" alt="image-20210412115051301" style="zoom:80%;" />

<p>浏览器输入</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:9870</span><br></pre></td></tr></table></figure>

<p>如果端口不对，可以查阅hadoop官方文档（对饮版本的<code> hdfs-default.xml</code> 配置文档，<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">3.2.2版本文档</a>)</p>
<img src="HDFS集群搭建.assets/image-20210412122424773.png" alt="image-20210412122424773" style="zoom:80%;" />

<p>打开界面是这样的</p>
<p>然后还可以看yarn的监控界面</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:8088</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412122859868.png" alt="image-20210412122859868" style="zoom:80%;" />

<p>以上端口都是默认配置端口，可以去修改对应配置文件改掉的</p>
<p>==<strong>但是吧，这样打开的页面非常不流畅，很卡顿，所以建议使用下面的方法2</strong>==</p>
<h3 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h3><p>由于我服务器在内网，我本机电脑也在内网</p>
<p>直接本机浏览器用<code> &lt;服务器ip&gt;:&lt;端口&gt;</code> 访问就好了</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420112514688.png" alt="image-20210420112514688"></p>
<p>如果不行的话，可以检查一下网络配置</p>
<h2 id="Hadoop关闭"><a href="#Hadoop关闭" class="headerlink" title="Hadoop关闭"></a>Hadoop关闭</h2><p>进入脚本文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd $HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<img src="HDFS集群搭建.assets/image-20210412123445406.png" alt="image-20210412123445406" style="zoom:80%;" />

<p>关闭所有</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./stop-all.sh</span><br></pre></td></tr></table></figure>

<p>也可以分步关闭：</p>
<ul>
<li><p>Step 1 关闭yarn计算框架（控制mapreduce的）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./stop-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li><p>Step 2 关闭文件系统</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./stop-dfs.sh</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>==注意：分步关闭的顺序刚好和分步启动相反==</strong></p>
<p>这里，我选用关闭所用</p>
<img src="HDFS集群搭建.assets/image-20210412124003275.png" alt="image-20210412124003275" style="zoom:80%;" />

<p>查看一下jps和report</p>
<img src="HDFS集群搭建.assets/image-20210412124059850.png" alt="image-20210412124059850" style="zoom:80%;" />

<p>可以看到集群已经关闭</p>
<h2 id="一个问题：只能检测到一个datanode"><a href="#一个问题：只能检测到一个datanode" class="headerlink" title="一个问题：只能检测到一个datanode"></a>一个问题：只能检测到一个datanode</h2><img src="HDFS集群搭建.assets/image-20210420103741848.png" alt="image-20210420103741848" style="zoom:100%;" />

<p>可以看到，查看集群监控状态时，存活的datanode只有master自己一个，但是slave1、2确实已经 启动了</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420103900740.png" alt="image-20210420103900740"></p>
<p>slave1、2上都能看到DataNode进程被启动了</p>
<h3 id="解决方法：关闭防火墙即可"><a href="#解决方法：关闭防火墙即可" class="headerlink" title="解决方法：关闭防火墙即可"></a>解决方法：关闭防火墙即可</h3><p>三台机子都执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105427601.png" alt="image-20210420105427601"></p>
<p>将防火墙关闭，然后关闭重启集群</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105548350.png" alt="image-20210420105548350"></p>
<p>再次查看状态监控</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105641583.png" alt="image-20210420105641583"></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420105657842.png" alt="image-20210420105657842"></p>
<p>可以看到现在live datanode有3个了，能检测到slave1、2了</p>
<h3 id="补充：查看节点版本信息"><a href="#补充：查看节点版本信息" class="headerlink" title="补充：查看节点版本信息"></a>补充：查看节点版本信息</h3><p>可以在从节点看一下datanode的Version信息</p>
<p>路径在：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $HADOOP_HOME/data/tmp/dfs/data/current</span><br><span class="line">cat VERSION</span><br></pre></td></tr></table></figure>

<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420113826254.png" alt="image-20210420113826254"></p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420113844349.png" alt="image-20210420113844349"></p>
<p>注意到slave1、2的storageID和datanodeUuid应该是不同的</p>
<p>同样也可以看master的信息，它技既作为datanode也是namenode，所有有data和name两个文件夹</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420114040018.png" alt="image-20210420114040018"></p>
<p>先看data的VERSION</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420114127098.png" alt="image-20210420114127098"></p>
<p>再看name的VERSION</p>
<p><img src="HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.assets/image-20210420114334082.png" alt="image-20210420114334082"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><strong>主要参考：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Kf4y1z7Nw">Hadoop保姆级超详细安装教程</a>  — 版本是 2.7.7</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41094332/article/details/104544449">hadoop3.1.3 分布式集群搭建的详细教程</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/bingduanlbd/article/details/51914550">深入理解HDFS：Hadoop分布式文件系统</a></li>
</ul>
<p>其他参考资料：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41685388/article/details/102639751">https://blog.csdn.net/weixin_41685388/article/details/102639751</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/gulugulu_gulu/article/details/105724788">https://blog.csdn.net/gulugulu_gulu/article/details/105724788</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/fanxin_i/article/details/80425461">https://blog.csdn.net/fanxin_i/article/details/80425461</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45976734/article/details/111658764">https://blog.csdn.net/weixin_45976734/article/details/111658764</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" data-id="cknravc1i00003o3b00hz0ekh" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2021/04/21/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/04/21/HDFS%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/04/21/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>